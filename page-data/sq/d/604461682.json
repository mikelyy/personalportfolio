{"data":{"jobs":{"edges":[{"node":{"frontmatter":{"title":"Senior Software Engineer","company":"Visa","location":"Foster City, CA","range":"November - Present","url":"https://usa.visa.com/"},"html":"<ul>\n<li>Coming up soon</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Data Science Engineer Intern","company":"BJs Wholesale Club","location":"Westborough, MA","range":"June - August 2020","url":"https://www.bjs.com/"},"html":"<ul>\n<li>Developed an automated tool for transforming address for BJs existing membership by Python and ArcGIS API, reaching 0.95 accuracy compared to the existing tool.</li>\n<li>Created data pipelines to clean, transform and combine over 1 million members' demographic and location data stored in AWS S3, expected to reduce manual processing time by 100 man-hours per year.</li>\n<li>Utilized Agile methodologies such as Jira and Confluence to collaborate cross-functionally with teams to understand member engagement KPIs.</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Quantitative Analyst Intern","company":"HuaTai Securities Co., Ltd.","location":"Beijing, China","range":"June - August 2019","url":"https://www.htsc.com.cn/htzq/investor/en/about.jsp"},"html":"<ul>\n<li>Utilized Wind Terminal to construct macro indicator database; built a new multi-factor model (industry level, individual stock, sentimental index), conducted back test through MATLAB; increasing excess return rate by 3%.</li>\n<li>Developed different models (Black-Litterman, Markowitz Mean-Variance, Most-Diversified Portfolio) to optimize portfolio strategies.</li>\n<li>Conducted statistical analysis on log-return of stocks through Shapiro-Wilk test, ACF and PACF plots, ADF test and White Noise test; implemented seasonal decomposition and HP filters; built AR, MA, and ARMA Time Series models through Python.</li>\n</ul>"}},{"node":{"frontmatter":{"title":"Data Analyst Intern","company":"58.com","location":"Beijing, China","range":"May - June 2018","url":"https://bj.58.com/"},"html":"<ul>\n<li>Implemented ETL process on housekeeping company data in Python to compare them based on their services and prices; interacted with department's record system in real time.</li>\n<li>Obtained 1000+ lines of shopping information using Beautiful Soup and stored them into MySQL; leveraged business intuition to assign label regarding address type (office vs community).</li>\n<li>Collected data and feedback from Baidu Index website and social media platforms; wrote a report on user behavior.</li>\n</ul>"}}]}}}